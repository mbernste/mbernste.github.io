---
title: "A framework for making sense of metrics in technical organizations"
date: 2026-02-07
permalink: /posts/metrics/
tags:
  - metrics
  - leadership
---

_THIS POST IS CURRENTLY UNDER CONSTRUCTION_

_If you work in a quantitative or technical field, there is little doubt that you or your team has worked long and hard to define which metrics to measure and track. Using data-driven metrics is a critical practice for making rational decisions and deciphering truth in a complex and noisy world. However, as others have pointed out, an over-reliance on metrics can lead to poor outcomes. In this post, I propose a mental model for conceptualizing metrics. In this framework, I will categorize metrics into two groups: exploratory metrics and value-approximating metrics. Value-approximating metrics are the most dangerous, since they form the objective functions around which the organization seeks to optimize._

Introduction
------------

For good reason, the importance of data-driven reasoning is deeply ingrained in the culture of quantitative and technical disciplines. At the same time, the systems we both build and operate within are too complex to be fully grasped by the human mind. To understand them, we must measure them. The combined consequences of our secular cultural traditions, and the simple need to understand complex systems, lead technical organizations to fixate on **metrics**. This reliance on metrics is deeply ingrained. Managers repeat quotes like, "You can't manage what you can't measure." Software engineers create dashboards and databases to track metrics. Meetings often begin with an overview of where the project or business stands in terms of the metrics.

I would by no means be the first to point out that an over-reliance on metrics can lead to poor outcomes. For example, [Goodhart's Law](https://en.wikipedia.org/wiki/Goodhart%27s_law) states, "When a measure becomes a target, it ceases to be a good measure." As Jeff Bezos [has pointed out](https://www.youtube.com/watch?v=8ij964FCQiw), organizations often end up managing the "proxy for truth” rather than the thing they actually value.

In this blog post, I will present a mental framework for thinking about metrics that lets us more precisely articulate the kinds of failure modes that an over-reliance on metrics can lead to. 


Systems as high-dimensional objects
-----------------------------------

Before we get to discussing metrics, we will first generalize the system being measured as a [high-dimensional](https://mbernste.github.io/posts/intrinsic_dimensionality/) object in some abstract space (akin to a [vector space](https://mbernste.github.io/posts/vector_spaces/)). By "system", I mean any complicated thing that a given technical organization seeks to understand or improve. 

For example, such a system under consideration might be an entire business; Businesses are complicated "high-dimensional" objects in that they have many components: employees, processes, capital, debt, revenue, and so on. A piece of technology, like a website, that an organization is building is also such a system. For example, a website has many components: traffic, latency, lines of code, vulnerability, etc. A machine learning algorithm is also such a system with many characteristics: accuracy, precision, recall, computational cost, etc.

In a very abstract way, one can imagine that any given system resides in a "space" comprising other similar systems. For simplicity, let's take a business: We can summarize a business in terms of a large list of numbers like number of employees, sales per month, cost of goods sold, cash on hand, debt... (the list can go on an on). Given such a list (which could be extremely long), we can place the business in a coordinate vector space where each location in the vector space is some (possibly non-existent) business. A schematic showing three dimensions is shown below:

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/business_as_vectors_metrics.png" alt="drawing" width="550"/></center>

We will denote this space of possible systems (e.g., businesses) as $\mathcal{X}$. A given system $x$ is a member of $\mathcal{X}$, denoted $x \in \mathcal{X}$.


Value functions tell you how "good" a system is
-----------------------------------------------

We consider cases in which the goal of an organization to either improve some system under measurement, $x \in \mathcal{X}$, or,at the very least, to assess how "good" the system is in terms of some subjective or economic measure of value. 

At risk of being pedantic, let's define a **value function** to be a function $V$ that maps systems in $\mathcal{X}$ to real numbers that quantify the value of those systems:

$$V : \mathcal{X} \rightarrow \mathbb{R}$$

That is, $V(x)$ tells us how much to value system $x$. If we have two systems, $x_1$ and $x_2$, then $V(x_1) > V(x_2)$ tells us we should prefer $x_1$ to $x_2$. We can depict this schematically in a small, two-dimensional space of systems with a heatmap. Below is a toy example:

In some situations, the value function is obvious. For example, when considering a business, the value function might simply be its _profitability_. However, in other cases, the value function is not so easy to define. A premier example in this situation is judging the aesthetic value of art. Though I would also argue that even in technical fields, where the system under study _should_ admit an easy-to-define value function, it is often not as clear-cut as one would hope. Take for example an algorithm that automates making medical diagnoses -- say, an algorithm for detecting tumors in medical imaging data. One could argue that accuracy alone is not the key value function since false positives have very different costs than false negatives. In truth, the value function should track something like, "expected benefit versus harm", but here that is quite difficult to define! 

Metrics are functions that can be either exploratory or value-approximating
---------------------------------------------------------------------------

Using this same framework, we can define a **metric** to be some function that, like $V$, projects a system, $x \in \mathcal{X}$, to a number. That is, we can define a metric, $f$, as a function

$$f: \mathcal{X} \rightarrow \mathbb{R}$$

Metrics fall into two fundamentally different categories: those that are intended to approximate the value function $V$, and those that are intended purely to explore and describe the structure of $\mathcal{X}$. These two uses impose very different requirements. A value-approximating metric makes an implicit claim about the relationship between $f$ and $V$
To rely on such a metric, one must understand where this approximation holds. Exploratory metrics, by contrast, make no claim about value at all. I believe that making a clear distinction between these kinds of metrics can bring clarity to discussions around them.

### Exploratory metrics: Those that seek to describe $\mathcal{X}$

In many cases, organizations do not seek to necessarily approximate the value function, but instead simply seek to understand will create a _collection_ of metrics, each describing some specific aspect of the system: $f_1, f_2, ..., f_M$. These metrics In this way, one can reduce a complex, high-dimensional system down into the space of a few dimensions:

$$f_1(x), f_2(x), \dots, f_M(x)$$

In this sense, metrics act as a form of [dimensionality reduction]().

Put another way, these metrics behave like the [Seven Blind Mice](https://en.wikipedia.org/wiki/Seven_Blind_Mice) by Ed Young. Each blind mouse is feeling one particular aspect of the elephant. Only by feeling the entire elephant does the seventh mouse understand that the object is an elephant. Likewise, our central goal is to determine the true ["shape"](https://mbernste.github.io/posts/understanding_3d/) of the system.

### Value-approximating metrics: Those that seek to approximate $V$

There are many ways in which a given metric $f$ may succeed or fail at approximating $V$. Depending on what scenario one is in, one has a specific challenge that they must 

* **Proportionality:** In this situation, the metric $f$ is _proportional_ to $V$. That is $V(x) = cf(x)$ for some unknown constant $c$. Because $c$ is unknown, it is impossible to know _exactly_ when one has succeeded at achieving a sufficient value of $V$; however, one can confidently track progress.
* **Monotonicity:** In this situation, the metric $f$ increases monotonically with $V$. That is, if $f$ increases, then so does $V$; however, it is not clear by how much $V$ increases. In some regimes, $f$ and $V$ may be tightly linked whereas in others there is a vast difference in how much $V$ increases with respect to $f$.
* **Noisy correlation:** In this situation, $f$ _roughly_ tracks $V$, in that the two are correlated, but there is substantial noise.
* **Local approximation:** In this situation $f$ tracks $V$ in _some regimes_, but diverges in others.


Restating Goodhart's Law with this framework
--------------------------------------------

One benefit of this formalism is that it lets us state well-known phenomena more precisely. As an example, we can use it to articulate a common failure mode often summarized by Goodhart’s Law. XXXX DISCUSSION OF GRADIENTS. EXAMPLE PLOT AND EXPLANATION XXXXXX

Not all systems admit an accurate value-measuring metric
--------------------------------------------------------

Sometimes, because the value function is so complex, it is just not possible to develop a metric that tracks it accurately enough to be relied upon. I do believe that this kind of situation is not uncommon. Many "functions" or "mappings" in the real world are incredibly noisy, unintuitive, and non-linear. In fact, the very success of machine learning as a discipline is driven by the way in which algorithms learn complex mappings in data.

When one is confronted with an intractible value-function, it is often wiser to admit this outright than to spend valuable time and energy on finding an elusive value-approximating metric. Relying on a poor value-approximator is a road to ruin and is exactly what Bezos warns against in his message on "proxies". 

**Sometimes, one just has to admit defeat: We can't quantify "good" even though we know it when we see it.**

<center><img src="https://raw.githubusercontent.com/mbernste/mbernste.github.io/master/images/metric_meme.png" alt="drawing" width="500"/></center>

<br>

This is indeed a challenging situation to find oneself. It means that one cannot rely upon an easy, automated way to assess the state of the system and to make decisions. One may feel lost at sea without a compass! But, I would argue that this situation _can_ be navigated, and to do so, one must first acknowledge that one is lost! Once the limitations are acknowledged, organizations can plan around them rather than unknowingly optimize a poor proxy.

For example, if we know that evaluating $V$ requires human judgment that cannot be automated via a metric, we can allocate resources accordingly such as building processes that explicitly incorporate subjective assessment. 













CONSTRUCTION


The practice of using data to guide decisions and draw conclusions has arguably been a driving force behind humanity’s transition from subsistence living to a society characterized by relative comfort and abundance. 







Metrics fall into two categories: exploratory and value-approximating
---------------------------------------------------------------------

Now, using this same framework, we can define a **metric** to be some function that projects a system, $x \in \mathcal{X}$ to a real number. That is, we can define a metric, $f$, as a function

$$f: \mathcal{X} \rightarrow \mathbb{R}$$

Such examples abound: A simple metric for a business is _revenue_, which can be computed by summing over all of the transactions). A simple metric for a medical diognistics algorithm is _accuracy_, which is the number of correct diagnoses divided by the number of total diagnoses.

How a metric is used depends a lot on what the organization wants from these metrics. At a high-level, I see two primary ways that an organization uses metrics: to explore the space of $\mathcal{X}$ or to approximate the value function $V$.

### Exploratory metrics: Those that seek to describe $\mathcal{X}$

In many cases, organizations do not seek to necessarily approximate the value function, but instead simply seek to understand will create a _collection_ of metrics, each describing some specific aspect of the system: $f_1, f_2, ..., f_M$. These metrics In this way, one can reduce a complex, high-dimensional system down into the space of a few dimensions:

$$f_1(x), f_2(x), \dots, f_M(x)$$

Here, a collection of metrics serves as a form of [dimensionality reduction](https://mbernste.github.io/posts/dim_reduc/) -- that is, they take a high-dimensional object and compress it down into a lower-dimensional object that is easier to understand.

### Value-approximating metrics: Those that seek to describe $V$

In many, an organization is seeking to approximate, or define, the value function $V$. That is, they choose a metric $f$ and this metric serves as a _proxy_ for $V$. This is thus, a more formal way to describe Bezos's description of how organizations use metrics as "proxies" for value.


frame a system as a complex [high-dimensional](https://mbernste.github.io/posts/intrinsic_dimensionality/) object -- the system under consideration might be a business, service, process, or technology. There exists some theoretical "value function" that maps systems to a number that tells us how "good" that system is. We don't necessarily know what that value function looks like, so we develop metrics, which are themselves projections of the high-dimensional systems under consideration onto the real number line. Metrics can then be categorized by both their properties and by their relationship to the true value function. With this framework, we can reason about what makes some metrics more prone to misuse than others. Let's get started.

This was articulated clearly by [Lord Kelvin](https://en.wikipedia.org/wiki/Lord_Kelvin) [in 1883](https://en.wikiquote.org/wiki/William_Thomson):

<div style="font-style: italic; max-width: 500px; padding-left: 15px; border-left: 3px solid #ccc;">I often say that when you can measure what you are speaking about, and express it in numbers, you know something about it; but when you cannot measure it, when you cannot express it in numbers, your knowledge is of a meagre and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely, in your thoughts, advanced to the stage of science, whatever the matter may be. ~ Lord Kelvin</div>

<br>

For example, say we are a film studio where we seek to assess which movie script we should fund. It goes without saying that, if we consider $\mathcal{X}$ to be the space of movie scripts, the hypothetical function, $V$, would be quite difficult to define.

The example of a film studio is quite extreme; I think most people would take as obvious that judging objects of artistic expression cannot be approached quantitively (that being said, [companies are trying!](https://www.theverge.com/2019/5/28/18637135/hollywood-ai-film-decision-script-analysis-data-machine-learning)). 


[Jeff Bezos](https://en.wikipedia.org/wiki/Jeff_Bezos) did well in articulating the process by which a metric "ceases to be a good measure"; In a [recent podcast interview](https://www.youtube.com/watch?v=8ij964FCQiw), Bezos describes how organizations can target a metric as a _proxy_ for seomthing the organization _actually_ value. Over time, that proxy becomes a poor approximation for that true thing of value:

<div style="font-style: italic; max-width: 500px; padding-left: 15px; border-left: 3px solid #ccc;">One of the things that happens in business is that you develop certain things that you’re managing to. The typical case would be a metric. And that metric isn’t the typical underlying thing. Maybe the metric is something like the number of returns you get per unit sold… And so what happens is a little bit of a kind of inertia sets in where somebody a long time ago invented that metric… and they had a reason why they chose that metric. And then fast forward five years and that metric becomes the proxy for truth… Let’s say that metric is a proxy for customer happiness. That metric is not actually customer happiness; it’s a proxy for customer happiness. The person who invented the metric understood that connection. Five years later… you forget the truth behind why you were watching that metric in the first place. And then the world shifts a little bit. And now that proxy isn’t as valuable as it used to be. Or it’s missing something. ~ Jeff Bezos</div>

<br>


The cost of a false positive (i.e., a diagnosis of cancer where there is actually no cancer) is needless medical expenses and emotional stress. The cost of a false negative is a failure to detect cancer. How do we weight these two?



Recognizing a system does not admit a reliable value-approximating metric clarifies where rigor must come from. In such cases, the failure is not the absence of a metric, but the pretense that one exists. 
